{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note this code will only run when creating a Kaggle notebook from https://www.kaggle.com/kmader/rsna-bone-age. Datasets do not exist within this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we bridge the gap between the training dataset df and the training images by adding path_to_data to the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/kaggle/input/rsna-bone-age'\n",
    "\n",
    "df = pd.read_csv(os.path.join(base_dir, 'boneage-training-dataset.csv'))\n",
    "df['path_to_data'] = df['id'].map(lambda row_id: os.path.join(base_dir, 'boneage-training-dataset', 'boneage-training-dataset', '{}.png'.format(row_id)))\n",
    "df['exists'] = df['path_to_data'].map(os.path.exists)\n",
    "print(df['exists'].sum(), 'images found of', df.shape[0], 'total images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we take a look at what the data looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at an image\n",
    "img = mpimg.imread(df.iloc[0]['path_to_data'])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to prepare the image files for training by relying on Keras' built-in image preprocessing functions load_img() and img_to_array()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create our input df solely of images\n",
    "img_rows = 144\n",
    "img_cols = 144\n",
    "# Let's map the paths to the actual images\n",
    "imgs = df['path_to_data'].apply(lambda img_path: load_img(img_path, target_size=(img_rows, img_cols), color_mode='grayscale'))\n",
    "scaled_imgs = np.array([img_to_array(img)/255 for img in imgs]) # We want to bring all 0-255 pixel values between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Our first layer will be a convolutional layer\n",
    "model.add(Conv2D(12, kernel_size=(4,4), activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(20, kernel_size=(4,4), activation='relu'))\n",
    "model.add(Conv2D(20, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "\n",
    "# Our final layer is a single node because we will be predicting a continuous variable in bone age\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scaled_imgs, df['boneage'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
